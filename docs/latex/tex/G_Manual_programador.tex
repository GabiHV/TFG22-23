\apendice{Documentación técnica de programación}

\section{Introducción}
En esta sección se incluyen la documentación técnica del programador, presentando la estructura de directorios del proyecto, junto con el manual para realizar la correcta 
instalación y ejecución de este. 

\section{Estructura de directorios}
El proyecto cuenta con la siguiente estructura de directorios:
\begin{itemize}
    \item \textbf{/data/:} directorio que contiene los diferentes datos del proyecto, tanto procesados, sin procesar y los datos integrados que se emplearán en el modelado.
    \subitem \textbf{/data/raw/:} directorio con los datos sin procesar (únicamente con la selección previa de validez).
    \subitem \textbf{/data/processed/:} directorio con los datos procesados.
    \subitem \textbf{/data/integrated/:} directorio con los datos integrados en un único fichero.
    \item \textbf{/img/graphics/:} directorio con las diferentes gráficas resultado de la ejecución de los scripts de graficado.
    \item \textbf{/scripts/:} directorio con los scripts para la instalación de los entornos virtuales de Python junto con los requerimientos para ejecutar todos los ficheros
        fuente del proyecto.
    \item \textbf{/src/:} directorio con los diferentes ficheros fuente y variables de entorno y globales.
    \item \textbf{/models/:} directorio con los diferentes modelos obtenidos en el proceso final. Uno subdirectorio para cada diferente modelo neuronal implementado.
\end{itemize}

\section{Manual del programador}
En esta subsección se explicará cómo realizar una correcta descarga e instalación de los entornos necesarios para llevar a cabo la ejecución del proyecto.

Para descargar todo el contenido es necesario tener instalado en el sistema \textbf{Git}. Es posible clonar el repositorio introduciendo en la consola de 
git: 
\begin{lstlisting}[language=Bash]
    git clone https://github.com/GabiHV/TFG22-23
\end{lstlisting}

De igual forma, para poder llevar a cabo la ejecución e instalación del resto de las dependencias es necesario tener instalado \textbf{Python 3.9.13} en el
caso de realizar las ejecuciones con CPU.

\subsection{Ejecución de los scripts mediante CPU}
Para instalar el intérprete del lenguaje empleado en el proyecto se debe acudir a la página web oficial de los desarrolladores y descargar el ejecutable de instalación oficial.
La instalación puede realizarse en el siguiente enlace \cite{misc:python2023}.
En la fuente mencionada se pueden escoger diferentes formas de instalación. Dependiendo del sistema operativo utilizado en la máquina en la que se ejecutará el proyecto se debe seleccionar una
u otra y seguir los pasos establecidos.

Durante el desarrollo del proyecto se empleó como entorno de programación Visual Studio Code \cite{misc:code2023}, sin embargo, para su ejecución podemos emplear otros entornos como 
Anaconda Navigator \cite{misc:conda2023}.
Se explicará los pasos a seguir con el editor mencionado para habilitar los entornos, puesto que simplifica el trabajo al disponer de scripts que realizan de forma automática 
la instalación de las dependencias.
Los ficheros mencionados se encuentran en el directorio \textbf{/scripts/}.

Para ejecutar el script correspondiente al entorno de PowerShell de Windows se necesita establecer la política que lo permita. Para ello se debe abrir la terminal mencionada
como administrador del sistema e introducir: 
\begin{lstlisting}[language=Bash]
    Set-ExecutionPolicy Unrestricted    
\end{lstlisting}

Tras esto, se puede introducir el siguiente comando para iniciar el proceso de instalación: 
\begin{lstlisting}
    ./Virtual_env.ps1
\end{lstlisting}

Para ejecutar el script en el CMD de Windows se introduce:
\begin{lstlisting}[language=Bash]
    virtual_env.bat
\end{lstlisting}

De forma similar en Linux Bash:
\begin{lstlisting}[language=Bash]
    chmod +x virtual_env.sh && ./virtual_env.sh    
\end{lstlisting}

Una vez finalice el proceso de instalación de todas las dependencias se podrán ejecutar los diferentes ficheros fuente de Python Notebook abriendo el proyecto en Visual Studio Code
y estableciendo el Kernel de ejecución al entorno configurado (Figura \ref{fig:venv_selection.png}).
Está definido que el entorno virtual se denomine \textbf{.venv}, por lo que será necesario buscar entre los diferentes 
instalados haciendo clic en la parte superior derecha del notebook (en el botón para la selección del intérprete de ejecución).

\imagen{venv_selection.png}{Búsqueda del entorno virtual}{1}

\imagen{venv_selected.png}{Selección del entorno virtual}{0.25}

Posteriormente podrá ejecutarse cualquier fichero Pyhton Notebook con el botón de ``Execute All'', o proceder por celda.

En lo referente a los ficheros fuente de Python, con el entorno virtual instalado abriendo una consola en el sistema operativo en \textbf{/.venv/bin/} en Linux y \textbf{/.venv/Scripts/}
en Windows, podremos ejecutar la activación del entorno con los scripts incluidos en el directorio (ejecutando \linebreak \textbf{activate.bat} y \textbf{Activate.ps1} en Windows dependiendo del terminal empleado).
Esta operación se realizará automáticamente al realizar la instalación de los módulos de Python incluidos en el fichero de requerimientos, por lo que se puede aprovechar la terminal en ejecución para 
este propósito.

Para ejecutar los ficheros de Python adecuadamente es necesario estar situados con la terminal en el directorio correspondiente. En este caso se debe navegar hasta \textbf{./src/}

\subsection{Ejecución acelerada mediante GPU: CUDA}
Para disminuir el tiempo de entrenamiento de los modelos puede realizarse una instalación de un contenedor de Docker que emplea la tecnología
CUDA (plataforma de computación paralela desarrollada por NVIDIA \cite{misc:wikiCuda}) e incorpora las librerías necesarias de TensorFlow.

Para ello, es necesario disponer de una tarjeta gráfica de la marca mencionada compatible con una versión de CUDA mayor a 11.7, al mismo tiempo
que actualizar sus \textit{drivers} a la última versión estable disponible.

Para realizar la instalación en un sistema Windows es necesario disponer a su vez del WSL (Windows Subsystem for Linux) activo y funcionando con una distribución
de Ubuntu.
Se puede instalar la tecnología mencionada ejecutando la PowerShell en modo administrador e introduciendo:
\begin{lstlisting}[language=Bash]
    wsl --install
\end{lstlisting}

Al finalizar se deberá crear el entorno de Linux siguiendo los pasos indicados en la terminal para posteriormente establecer el usuario
de WSL.
Los siguientes pasos serán comunes.

Es necesario situarse en la carpeta principal del proyecto para poder realizar una correcta inicialización del contenedor. 
Si Docker ya se encuentra instalado en el sistema, únicamente se debe ejecutar el script \textbf{docker-create.sh} (se recomienda una instalación limpia para evitar
posibles incompatibilidades), en caso contrario,
previamente ejecutar \textbf{docker-install.sh}. Ambos con permisos de superusuario (empleando \textit{sudo}).

Tras iniciar el contenedor se creará el servicio de Jupyter Notebook al que podremos acceder mediante el navegador con:
\begin{lstlisting}
    https://localhost:8888/?token=<token>
\end{lstlisting}

De esta forma, como se muestra en la Figura \ref{fig:execDocker.png}, \textbf{<token>} podrá obtenerse del terminal en el que se encuentra corriendo
el contenedor.

\imagen{execDocker.png}{Ejecución del servicio de Jupyter Notebook con GPU}{1}

Tras esto, se puede acceder desde Jupyter a los ficheros \textbf{.ipynb} para ejecutarlos según la necesidad.

\subsection{Ejecución acelerada mediante GPU: Google Colab}
Si no se dispone de una tarjeta gráfica compatible con CUDA puede emplearse Google Colab para realizar la ejecución acelerada del entrenamiento.
Para ello, se debe abrir el proyecto desde la plataforma mencionada, de forma que se dispongan de los datos en \textbf{./data/integrated\_data} 
(pueden crearse para ello las estructuras de directorios necesarios) y el Python Notebook a ejecutar.

Debe cambiarse, por otro lado, el tipo de entorno de ejecución, seleccionando en \textbf{Entorno de ejecución > Seleccionar entorno de ejecución}
la opción \textit{``GPU''} en \textit{``Acelerador por hardware''} como se muestra en la Figura \ref{fig:googleColabGPU.png}.

\imagen{googleColabGPU.png}{Selección de GPU en Google Colab}{0.75}

\section{Pruebas del sistema}
En esta subsección se presentará la forma de realizar las modificaciones en los hiperparámetros de los modelos, de forma que estos puedan variar de acuerdo con los nuevos requerimientos introducidos.

Los modelos contienen los siguientes hiperparámetros:
\begin{itemize}
    \item \textbf{learning\_rate:} ratio de aprendizaje empleado en la variación de los pesos en los modelos neuronales.
    \item \textbf{batch\_size:} tamaño del conjunto de datos que se emplea en una única iteración en el proceso
        de aprendizaje.
    \item \textbf{epochs:} cantidad de épocas que se entrenará cada modelo.
    \item \textbf{window\_size\_inputs:} tamaño de la ventana de datos que se introduce como datos de entrada al modelo
        (se corresponde con el número de horas previas para realizar X predicciones).
    \item \textbf{window\_size\_targets:} tamaño de la ventana de datos que se emplean como datos a predecir.
    \item \textbf{train\_frac:} fracción del conjunto total de datos que se empleará para entrenar los modelos.
    \item \textbf{val\_frac:} fracción del conjunto total de datos que se empleará para validar los modelos, siendo el 
        \(1 - train\_frac - val\_frac\) la fracción del conjunto de test.
\end{itemize}

Por cada uno de los diferentes modelos se proporcionará una gráfica del error de entrenamiento y validación
durante el proceso correspondiente, además de las gráficas comparativas de los valores predichos y 
los reales por sensor y atributo, así como el error máximo total en cada característica para todos los sensores y las gráficas
de los errores en el conjunto de test, de forma que se 
pueda dar una idea de los valores en los que ronda el error en cada una de las variables. 

