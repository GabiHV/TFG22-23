\apendice{Evaluación}

\section{Introducción}
En esta fase se estima el rendimiento de los diferentes modelos, y, en su caso, 
se reconsideran los objetivos del proyecto, de manera que, si estos son poco efectivos,
se vuelve a la primera fase.

En todas las redes neuronales se ha empleado validación cruzada externa y, además, se realizarán
diferentes ejecuciones con diversos parámetros para conocer el rendimiento de estas, a 
la par que poder eliminar en cierta medida el efecto del azar en los modelos 
resultantes.

Para validarlos se realizarán pruebas variando el número de capas
ocultas, así como el de celdas/neuronas en cada una de estas y el ratio de aprendizaje.
De esta manera, se realizarán combinaciones con 1, 2 y 3 capas en cada uno de los modelos, 
así como 32, 16 y 8 celdas/neuronas y 0.1, 0.01 y 0.001 de ratio de aprendizaje. 

Por otro lado, se ha dividido el conjunto de datos original en un conjunto de entrenamiento del 75\% de los disponibles
por sensor, 15\% para validación siendo el restante de test.

Con respecto al número de muestras de entrada se emplearán 6 horas previas para realizar
una predicción a una hora vista, empleando un tamaño de bloque de 256 ejemplos (los modelos 
no se entrenan con todos los datos en todas las iteraciones, sino que se emplean un subconjunto).

Además, se emplea un planificador de la tasa de aprendizaje, de forma
que en la época 50 disminuye multiplicando \(lr * e^{-0.1}\), para, de esta manera,
centrar los esfuerzos en la región explorada.

Para cada una de las pruebas se realizarán 5 ejecuciones diferentes con 100 iteraciones, 
tomando como medida comparativa el error cuadrático medio de validación.

\section{Resultados de GRU}
En la Tabla \ref{tabla:Evaluación GRU} se presentan los errores cuadráticos medios
que se obtendrán por término medio con el modelo. 

\tablaSmallSinColores{Evaluación GRU}{l l l l}{Evaluación GRU}{\textbf{Capas} & \textbf{Tamaño capa} & \textbf{Learning rate} & \textbf{MSE GRU} \\}
{
    1 & 8 & 0.001 & 1.72183E-05 \\
    1 & 8 & 0.01 & 3.37952E-06\\
    1 & 8 & 0.1 & 0.00551\\
    1 & 16 & 0.001 & 9.1907E-06\\
    1 & 16 & 0.01 & 9.55771E-07\\
    1 & 16 & 0.1 & 0.00474\\
    1 & 32 & 0.001 & 4.50204E-06\\
    \textbf{1} & \textbf{32} & \textbf{0.01} & \textbf{5.96471E-07}\\
    1 & 32 & 0.1 & 0.00297\\

    % 2 capas ocultas
    2 & 8 & 0.001 & 1.56769E-05\\
    2 & 8 & 0.01 & 1.65277E-06\\
    2 & 8 & 0.1 & 0.00965\\
    2 & 16 & 0.001 & 5.07987E-06\\
    \textbf{2} & \textbf{16} & \textbf{0.01} & \textbf{5.66822E-07}\\
    2 & 16 & 0.1 & 0.01148\\
    2 & 32 & 0.001 & 2.18717E-06\\
    \textbf{2} & \textbf{32} & \textbf{0.01} & \textbf{2.69205E-07}\\
    2 & 32 & 0.1 & 0.01727\\

    % 3 capas ocultas
    3 & 8 & 0.001 & 1.61179E-05\\
    3 & 8 & 0.01 & 1.42658E-06\\
    3 & 8 & 0.1 & 0.00706\\
    3 & 16 & 0.001 & 5.18860E-06\\
    \textbf{3} & \textbf{16} & \textbf{0.01} & \textbf{4.66034E-07}\\
    3 & 16 & 0.1 & 0.02418\\
    3 & 32 & 0.001 & 2.36664E-06\\
    3 & 32 & 0.01 & 8.90246E-07\\
    3 & 32 & 0.1 & 0.00976\\
}

Como puede observarse, los mejores resultados en términos generales les obtendremos 
con un \textit{learning rate} de 0.01.

\section{Resultados de LSTM}

\tablaSmallSinColores{Evaluación LSTM}{l l l l}{Evaluación LSTM}{\textbf{Capas} & \textbf{Tamaño capa} & \textbf{Learning rate} & \textbf{MSE LSTM} \\}
{
    1 & 8 & 0.001 & 2.12520E-05\\
    1 & 8 & 0.01 & 3.4556E-06\\
    1 & 8 & 0.1 & 3.9049E-06\\
    1 & 16 & 0.001 & 1.18867E-05\\
    1 & 16 & 0.01 & 1.31837E-06\\
    1 & 16 & 0.1 & 3.14115E-06\\
    1 & 32 & 0.001 & 5.84463E-06\\
    \textbf{1} & \textbf{32} & \textbf{0.01} & \textbf{6.62421E-07}\\
    \textbf{1} & \textbf{32} & \textbf{0.1} & \textbf{9.51891E-07}\\

    % 2 capas ocultas
    2 & 8 & 0.001 & 3.29916e-05\\
    2 & 8 & 0.01 & 4.94574-06\\
    2 & 8 & 0.1 & 6.85972E-06\\
    2 & 16 & 0.001 & 1.33461e-05\\
    2 & 16 & 0.01 & 1.23340e-06\\
    2 & 16 & 0.1 & 6.65626E-06\\
    2 & 32 & 0.001 & 5.63944E-06\\
    \textbf{2} & \textbf{32} & \textbf{0.01} & \textbf{4.56945E-07}\\
    2 & 32 & 0.1 & 4.20038E-06\\

    % 3 capas ocultas
    3 & 8 & 0.001 & 4.58400E-06\\
    3 & 8 & 0.01 & 5.90159E-06\\
    3 & 8 & 0.1 & 0.00031\\
    3 & 16 & 0.001 & 2.22344-05\\
    3 & 16 & 0.01 & 1.17654E-06\\
    3 & 16 & 0.1 & 0.00487\\
    3 & 32 & 0.001 & 8.16043E-06\\
    \textbf{3} & \textbf{32} & \textbf{0.01} & \textbf{6.54021E-07}\\
    3 & 32 & 0.1 & 0.00491\\
}

\section{Resultados de MLP}

\tablaSmallSinColores{Evaluación MLP}{l l l l}{Evaluación MLP}{\textbf{Capas} & \textbf{Tamaño capa} & \textbf{Learning rate} & \textbf{MSE MLP} \\}
{
    1 & 8 & 0.001 & 0.00076\\
    1 & 8 & 0.01 & 0.01218\\
    1 & 8 & 0.1 & 0.02064\\
    1 & 16 & 0.001 & 6.21736E-05\\
    1 & 16 & 0.01 & 0.00059\\
    1 & 16 & 0.1 & 0.02056\\
    1 & 32 & 0.001 & 1.33441E-05\\
    \textbf{1} & \textbf{32} & \textbf{0.01} & \textbf{5.57840E-06}\\
    1 & 32 & 0.1 & 0.02415E-05\\

    % 2 capas ocultas
    2 & 8 & 0.001 & 0.00094\\
    2 & 8 & 0.01 & 0.00673\\
    2 & 8 & 0.1 & 0.02428\\
    2 & 16 & 0.001 & 1.96797E-05\\
    2 & 16 & 0.01 & 0.00042\\
    2 & 16 & 0.1 & 0.01624\\
    2 & 32 & 0.001 & 8.32571E-06\\
    \textbf{2} & \textbf{32} & \textbf{0.01} & \textbf{5.56436E-06}\\
    2 & 32 & 0.1 & 0.02032\\

    % 3 capas ocultas
    3 & 8 & 0.001 & 0.00152\\
    3 & 8 & 0.01 & 0.00168\\
    3 & 8 & 0.1 & 0.02417\\
    3 & 16 & 0.001 & 5.74476E-05\\
    3 & 16 & 0.01 & 0.00031\\
    3 & 16 & 0.1 & 0.02035\\
    \textbf{3} & \textbf{32} & \textbf{0.001} & \textbf{6.49630E-06}\\
    \textbf{3} & \textbf{32} & \textbf{0.01} & \textbf{6.91262E-06}\\
    3 & 32 & 0.1 & 0.02028\\
}