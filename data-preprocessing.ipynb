{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de los datos para poder ser empleados por la _RNA_\n",
    "\n",
    "Importamos las librerías para el procesamiento de los datos.\n",
    "Para el proceso de limpieza de los datos inválidos y los outliers emplearemos Pandas.\n",
    "\n",
    "Por otro lado, en el caso de los datos del pluviómetro para comprobar los valores anómalos emplearemos la librería nativa de peticiones (requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import math as m\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las constantes para establecer la dirección en la que se encuentran los ficheros de datos y el directorio en el que se deberá almacenar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de directorios\n",
    "RAW_FILES_PATH = './data/raw_data'\n",
    "CLASSIFIED_FILES_PATH = './data/classified_data/'\n",
    "SENSOR_FILES_DIRECTORY = RAW_FILES_PATH + '/sensores/'\n",
    "PLUVIOMETER_FILES_DIRECTORY = RAW_FILES_PATH + '/pluviometro/'\n",
    "\n",
    "# URL de API meteorologica para realizar las comparaciones\n",
    "WEATHER_API_BASE_URL = 'https://history.openweathermap.org/data/2.5/history/city?lat=41.6966212&lon=-3.9284274&dt={dt}&units=metric&appid={key}'\n",
    "\n",
    "APIKEY = '9382de5e41593eeb1d830727d6df604d'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detección los valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(data):\n",
    "    # Ventana de datos agrupados por dia\n",
    "    rolling_win = data.groupby(pd.Grouper(freq=\"24H\", key=\"ts\"))\n",
    "\n",
    "    for _, group in rolling_win:\n",
    "        # Para cada columna realizamos el analisis por deteccion de valores atipicos\n",
    "        for col in data.columns:\n",
    "            if(col != 'ts'):\n",
    "                # Calculo de la media y la desviacion tipica del grupo\n",
    "                group_mean = group[col].mean()\n",
    "                group_std = group[col].std()\n",
    "                group_median = group[col].median()\n",
    "\n",
    "                # Definicion del umbral para los valores atipicos (se establece 1 vez la desviacion estandar)\n",
    "                threshold = 1.4 * group_std\n",
    "\n",
    "                # Identificacion de los valores atipicos\n",
    "                outliers = group[(group[col] - group_mean).abs() > threshold]\n",
    "\n",
    "                data.loc[data['ts'].isin(outliers['ts']), col] = group_median\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los ficheros de los datos relacionados con los sensores debemos realizar operaciones diferentes que en el archivo del pluviómetro, por lo que se divide el procesamiento en varias funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    sensor_files = os.listdir(SENSOR_FILES_DIRECTORY)\n",
    "    sensor_data_processing(sensor_files)\n",
    "    # pluviometer_data_processing()\n",
    "\n",
    "def sensor_data_processing(sensor_files):\n",
    "    for file in sensor_files:\n",
    "\n",
    "        dataset = pd.read_csv(SENSOR_FILES_DIRECTORY + file)\n",
    "\n",
    "        # Eliminamos los datos marcados como invalidos\n",
    "        dataset = dataset[dataset['validez'] != 0]\n",
    "\n",
    "        # Transformamos los timestamps en datetimes, para posteriormente poder\n",
    "        # agrupar los datos por dia.\n",
    "        dataset['ts'] = pd.to_datetime(dataset['ts'], unit=\"ms\")\n",
    "\n",
    "        # Eliminamos las columnas de fecha, h_C, h_L (por redundancia) y la columna\n",
    "        # de la bateria (no es esencial en la regresion).\n",
    "        # Por otro, lado deshechamos la columna de validez (no es necesaria)\n",
    "        dataset = dataset.drop(['fecha', 'h_C', 'h_L', 'bateria', 'validez'], axis=1)\n",
    "\n",
    "        # Eliminar nulos (data missing)\n",
    "        dataset = dataset.dropna()\n",
    "\n",
    "        # Eliminar outliers\n",
    "        outlier_detection(dataset)\n",
    "\n",
    "        dataset['ts'] = pd.to_numeric(dataset['ts'])\n",
    "\n",
    "        dataset.to_csv(CLASSIFIED_FILES_PATH + file, index = False)\n",
    "\n",
    "def pluviometer_data_processing():\n",
    "    pluviometer_files = [\"pluviometro.csv\"]\n",
    "\n",
    "    for file in pluviometer_files:\n",
    "        pluviometer_reader = pd.read_csv(SENSOR_FILES_DIRECTORY + file)\n",
    "\n",
    "        # Eliminar campos sin valores\n",
    "        pluviometer_reader = pluviometer_reader.dropna()\n",
    "\n",
    "        # Eliminar outliers\n",
    "        \n",
    "\n",
    "        pluviometer_reader.to_csv(CLASSIFIED_FILES_PATH + file, index = False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7f22e608a9410c9a00adbb49e3cb6a72010c497ae6b30c9496ff58de178a89c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
